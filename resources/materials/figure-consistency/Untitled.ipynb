{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import typing\n",
    "import random\n",
    "\n",
    "import pydantic\n",
    "import langchain_core\n",
    "import tqdm.auto\n",
    "import pandas as pd\n",
    "\n",
    "from consol.output_formats import AbstractOutput, ReasonedMixin, FloatOutput, ABCDEFOutput\n",
    "from consol.confidence_models import AbstractConfidenceModel, MsprtConfidenceModel, SprtConfidenceModel, PValueConfidenceModel, BayesianPosteriorConfidenceModel, VoteConfidenceModel\n",
    "\n",
    "class LlmModelEnum(enum.StrEnum):\n",
    "    GPT_4O = \"gpt-4o\"\n",
    "    GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "    O3_MINI_LOW = \"o3-mini-low\"\n",
    "    O3_MINI_MEDIUM = \"o3-mini-medium\"\n",
    "    O3_MINI_HIGH = \"o3-mini-high\"\n",
    "    OLLAMA_LLAMA3_1_8B = \"ollama:llama3.1:8b\"\n",
    "    OLLAMA_QWQ_32B = \"ollama:qwq:32b\"\n",
    "    GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n",
    "    GEMINI_2_0_FLASH_LITE = \"gemini-2.0-flash-lite\"\n",
    "\n",
    "\n",
    "class ConfidenceModelEnum(enum.StrEnum):\n",
    "    Msprt = \"msprt\"\n",
    "    Sprt = \"sprt\"\n",
    "    Pvalue = \"pvalue\"\n",
    "    BayesianPosterior = \"bayesian_posterior\"\n",
    "    Vote40 = \"vote40\"\n",
    "    Vote1 = \"vote1\"\n",
    "\n",
    "class OutputTypeEnum(enum.StrEnum):\n",
    "    Float = \"float\"\n",
    "    Abcdef = \"abcdef\"\n",
    "\n",
    "class ConfidentSolverConfig(pydantic.BaseModel):\n",
    "    llm_model: LlmModelEnum\n",
    "\n",
    "class ConfidentSolver:\n",
    "    def __init__(\n",
    "        self,\n",
    "        confidence_model: typing.Union[ConfidenceModelEnum, AbstractConfidenceModel],\n",
    "        answer_generator = typing.Generator[float, None, None],\n",
    "    ):\n",
    "        self.answer_generator = answer_generator\n",
    "\n",
    "        if confidence_model == ConfidenceModelEnum.Msprt:\n",
    "            self.confidence_model = MsprtConfidenceModel()\n",
    "        elif confidence_model == ConfidenceModelEnum.Sprt:\n",
    "            self.confidence_model = SprtConfidenceModel()\n",
    "        elif confidence_model == ConfidenceModelEnum.Pvalue:\n",
    "            self.confidence_model = PValueConfidenceModel()\n",
    "        elif confidence_model == ConfidenceModelEnum.BayesianPosterior:\n",
    "            self.confidence_model = BayesianPosteriorConfidenceModel()\n",
    "        elif confidence_model == ConfidenceModelEnum.Vote40:\n",
    "            self.confidence_model = VoteConfidenceModel()\n",
    "        elif confidence_model == ConfidenceModelEnum.Vote1:\n",
    "            self.confidence_model = VoteConfidenceModel(max_trials=1)\n",
    "        elif isinstance(confidence_model, AbstractConfidenceModel):\n",
    "            self.confidence_model = confidence_model\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown Confidence Model: {confidence_model}\")\n",
    "\n",
    "    def invoke(self, debug=False, **kwargs):\n",
    "        max_trials = self.confidence_model.config.max_trials\n",
    "        total_raw_outputs = []\n",
    "        with tqdm.auto.tqdm(total=max_trials, disable=True) as pbar:\n",
    "            while True:\n",
    "                first, second = self._get_top_two_answers(total_raw_outputs)\n",
    "                trials = self._determine_trials(first, second, max_trials, len(total_raw_outputs))\n",
    "                if trials == 0:\n",
    "                    pbar.close()\n",
    "                    break\n",
    "                raw_outputs = self._collect_raw_outputs(trials, **kwargs)\n",
    "                total_raw_outputs += raw_outputs\n",
    "                pbar.update(trials)\n",
    "        df = self._create_dataframe(total_raw_outputs)\n",
    "        if debug:\n",
    "            return df\n",
    "        return df['answer'].mode().iloc[0]\n",
    "\n",
    "    def _prepare_messages(self, input):\n",
    "        if isinstance(input, str):\n",
    "            return [langchain_core.messages.HumanMessage(input)]\n",
    "        return input\n",
    "\n",
    "    def _get_top_two_answers(self, total_raw_outputs):\n",
    "        total_ss = pd.Series([x['answer'] for x in total_raw_outputs]).value_counts()\n",
    "        two = total_ss.sort_values(ascending=False).head(2).to_list()\n",
    "        while len(two) < 2:\n",
    "            two += [0]\n",
    "        return two[0], two[1]\n",
    "\n",
    "    def _determine_trials(self, first, second, max_trials, current_trials):\n",
    "        for trials in range(0, max_trials + 1):\n",
    "            if first + trials == 0:\n",
    "                continue\n",
    "            if self.confidence_model.test(first + trials, second):\n",
    "                break\n",
    "        if trials >= max_trials - current_trials:\n",
    "            trials = max_trials - current_trials\n",
    "        return trials\n",
    "\n",
    "    def _collect_raw_outputs(self, trials, **kwargs):\n",
    "        raw_outputs = [{\n",
    "            'answer': answer,\n",
    "            'token_usage': 1,\n",
    "        } for answer in random.choices(self.answer_generator, k=trials)]\n",
    "        return raw_outputs\n",
    "\n",
    "    def _create_dataframe(self, total_raw_outputs):\n",
    "        return pd.DataFrame({\n",
    "            'answer': [x['answer'] for x in total_raw_outputs],\n",
    "            'token_usage': [x['token_usage'] for x in total_raw_outputs],\n",
    "        })\n",
    "\n",
    "df = ConfidentSolver(\n",
    "    answer_generator=[1,2,3],\n",
    "    confidence_model=\"bayesian_posterior\",\n",
    ").invoke(debug=True)\n",
    "print(df.answer.mode().iloc[0])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
