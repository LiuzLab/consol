{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaeyeonl/.local/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import typing\n",
    "import pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b4516d153448688033f420db7de868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import abc\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "import langchain\n",
    "import langchain_core\n",
    "import langchain_openai\n",
    "\n",
    "import tqdm.auto\n",
    "\n",
    "class FloatOutput(pydantic.BaseModel):\n",
    "    answer: float\n",
    "\n",
    "class ReasonedFloatOutput(pydantic.BaseModel):\n",
    "    reasons: typing.List[str]\n",
    "    answer: float\n",
    "\n",
    "\n",
    "class ConfidenceModel(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def test(self, first: int, second: int) -> bool:\n",
    "        pass\n",
    "\n",
    "class SprtConfidenceModelConfig(pydantic.BaseModel):\n",
    "    alpha: float\n",
    "    beta: float\n",
    "    p0: float\n",
    "    p1: float\n",
    "\n",
    "class SprtConfidenceModel(ConfidenceModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha = 0.05,\n",
    "        beta = 0.05,\n",
    "        p0 = 0.5,\n",
    "        p1 = 0.6,\n",
    "    ):\n",
    "        self.config = SprtConfidenceModelConfig(\n",
    "            alpha = alpha,\n",
    "            beta = beta,\n",
    "            p0 = p0,\n",
    "            p1 = p1,\n",
    "        )\n",
    "\n",
    "    def test(self, first, second) -> bool:\n",
    "        alpha, beta, p0, p1 = self.config.alpha, self.config.beta, self.config.p0, self.config.p1\n",
    "\n",
    "        logA = np.log((1 - beta) / alpha)\n",
    "        logB = np.log(beta / (1 - alpha))\n",
    "        logLR = first * np.log(p1 / p0) + second * np.log((1 - p1) / (1 - p0))\n",
    "        if logLR >= logA or logLR <= logB:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class PvalueConfidenceModelConfig(pydantic.BaseModel):\n",
    "    pvalue_threshold: float\n",
    "\n",
    "class PValueConfidenceModel(ConfidenceModel):\n",
    "    def __init__(self, pvalue_threshold = 0.05):\n",
    "        self.config = PvalueConfidenceModelConfig(pvalue_threshold=pvalue_threshold)\n",
    "\n",
    "    def test(self, first, second) -> bool:\n",
    "        pvalue_threshold = self.config.pvalue_threshold\n",
    "        pvalue = scipy.stats.binomtest(first, first+second, p=0.5, alternative='greater').pvalue\n",
    "        if pvalue <= pvalue_threshold:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class BayesianConfidenceModelConfig(pydantic.BaseModel):\n",
    "    confidence_threshold: float\n",
    "    priori: typing.Literal[\"jeffreys\", \"uniform\"]\n",
    "\n",
    "class BayesianConfidenceModel(ConfidenceModel):\n",
    "    def __init__(self, confidence_threshold = 0.95, priori = \"jeffreys\"):\n",
    "        self.config = BayesianConfidenceModelConfig(\n",
    "            confidence_threshold = confidence_threshold,\n",
    "            priori = priori,\n",
    "        )\n",
    "    def test(self, first, second) -> bool:\n",
    "        confidence_threshold, priori = self.config.confidence_threshold, self.config.priori\n",
    "\n",
    "        if priori == \"jeffreys\":\n",
    "            confidence = 1 - scipy.special.betainc(first + 0.5, second + 0.5, 0.5)\n",
    "        elif priori == \"uniform\":\n",
    "            confidence = 1 - scipy.special.betainc(first + 1, second + 1, 0.5)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid priori\")\n",
    "\n",
    "        if confidence >= confidence_threshold:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class VoteConfidenceModel(ConfidenceModel):\n",
    "    def test(self, first, second) -> bool:\n",
    "        _ = first, second  # Avoid linting error for unused arguments\n",
    "        return False\n",
    "\n",
    "class ConfidentSolverConfig(pydantic.BaseModel):\n",
    "    llm_model: typing.Literal[\"gpt-4o\", \"gpt-4o-mini\", \"o3-mini-low\", \"o3-mini-medium\", \"o3-mini-high\"]\n",
    "    confidence_model: typing.Literal[\"sprt\", \"pvalue\", \"bayesian\", \"vote\"]\n",
    "    output_schema: typing.Literal[\"float\", \"reasoned_float\"]\n",
    "    max_trials: int\n",
    "\n",
    "class ConfidentSolver:\n",
    "    def __init__(self, llm_model: str, confidence_model: str, output_schema: str, max_trials=40):\n",
    "        self.config = ConfidentSolverConfig(\n",
    "            llm_model=llm_model,\n",
    "            confidence_model=confidence_model,\n",
    "            output_schema=output_schema,\n",
    "            max_trials=max_trials\n",
    "        )\n",
    "        if llm_model in [\"gpt-4o\", \"gpt-4o-mini\"]:\n",
    "            llm = langchain_openai.ChatOpenAI(\n",
    "                model=llm_model,\n",
    "            )\n",
    "        elif llm_model in [\"o3-mini-low\", \"o3-mini-medium\", \"o3-mini-high\"]:\n",
    "            assert output_schema not in [\"reasoned_float\"]\n",
    "            llm = langchain_openai.ChatOpenAI(\n",
    "                model=\"o3-mini\",\n",
    "                reasoning_effort=llm_model.split(\"-\")[-1],\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"Unknown Model\")\n",
    "\n",
    "        if confidence_model == \"sprt\":\n",
    "            self.confidence_model = SprtConfidenceModel()\n",
    "        elif confidence_model == \"pvalue\":\n",
    "            self.confidence_model = PValueConfidenceModel()\n",
    "        elif confidence_model == \"bayesian\":\n",
    "            self.confidence_model = BayesianConfidenceModel()\n",
    "        elif confidence_model == \"vote\":\n",
    "            self.confidence_model = VoteConfidenceModel()\n",
    "        else:\n",
    "            raise Exception(\"Unknown Confidence Model\")\n",
    "\n",
    "        if output_schema == \"float\":\n",
    "            output_schema = FloatOutput\n",
    "        elif output_schema == \"reasoned_float\":\n",
    "            output_schema = ReasonedFloatOutput\n",
    "        else:\n",
    "            raise Exception(\"Unknown Output Schema\")\n",
    "\n",
    "        self.llm_with_structured_output = llm.with_structured_output(output_schema, include_raw=True)\n",
    "\n",
    "\n",
    "    def invoke(self, input, debug=False, **kwargs):\n",
    "        if isinstance(input, str):\n",
    "            messages = [langchain_core.messages.HumanMessage(input)]\n",
    "        else:\n",
    "            messages = input\n",
    "\n",
    "        max_trials = self.config.max_trials\n",
    "        total_raw_outputs = []\n",
    "        with tqdm.auto.tqdm(total=max_trials) as pbar:\n",
    "            while True:\n",
    "                total_ss = pd.Series([x['parsed'].answer for x in total_raw_outputs]).value_counts()\n",
    "                two = total_ss.sort_values(ascending=False).head(2).to_list()\n",
    "\n",
    "                while len(two) < 2:\n",
    "                    two += [0]\n",
    "                first, second = two\n",
    "\n",
    "                for trials in range(0, max_trials + 1):\n",
    "                    if first+trials == 0:\n",
    "                        continue\n",
    "                    if self.confidence_model.test(first+trials, second):\n",
    "                        break\n",
    "\n",
    "                if trials >= max_trials - len(total_raw_outputs):\n",
    "                    trials = max_trials - len(total_raw_outputs)\n",
    "\n",
    "                if trials == 0:\n",
    "                    break\n",
    "\n",
    "                raw_outputs = []\n",
    "                while len(raw_outputs) < trials:\n",
    "                    try:\n",
    "                        k = trials - len(raw_outputs)\n",
    "                        _ = self.llm_with_structured_output.batch([messages] * k, **kwargs)\n",
    "                        raw_outputs += [x for x in _ if x['parsed']]\n",
    "                    except Exception as e:\n",
    "                        print(f\"Unknown error during trial {len(raw_outputs)}/{trials} with input: {input}\", e, file=sys.stderr)\n",
    "                        continue\n",
    "                total_raw_outputs += raw_outputs\n",
    "                pbar.update(trials)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'answer': [x['parsed'].answer for x in total_raw_outputs],\n",
    "            'token_usage': [x['raw'].response_metadata['token_usage']['completion_tokens'] for x in total_raw_outputs],\n",
    "        })\n",
    "\n",
    "        if debug:\n",
    "            return df\n",
    "\n",
    "        return df['answer'].mode().iloc[0]\n",
    "\n",
    "solver = ConfidentSolver(\n",
    "    llm_model = \"gpt-4o-mini\",\n",
    "    confidence_model = \"vote\",\n",
    "    output_schema = \"float\",\n",
    ")\n",
    "\n",
    "solver.invoke(\"say 1\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
